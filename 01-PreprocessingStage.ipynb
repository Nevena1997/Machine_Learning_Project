{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing stage\n",
    "\n",
    "- Load train, validation and test datasets\n",
    "- Convert and resize images\n",
    "- Save new datasets\n",
    "<img src='https://user-images.githubusercontent.com/74012107/130700197-a35e8979-caee-445f-a02d-fa4ec4c9e6e2.png' width='1000' height='600'>\n",
    "\n",
    "### Datasets\n",
    "The original dataset is available at [Kaggle](https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset).\n",
    "- Train dataset - 10 000 images (5000 face images with masks and 5000 without masks)  \n",
    "- Validation dataset - 800 images (400 face images with masks and 400 without masks)\n",
    "- Test dataset - 992 images (483 face images with masks and 509 without masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:  ['WithMask', 'WithoutMask']\n",
      "Labels:  [0, 1]\n",
      "{'WithMask': 0, 'WithoutMask': 1}\n"
     ]
    }
   ],
   "source": [
    "categories = ['WithMask', 'WithoutMask']\n",
    "labels = [0, 1]\n",
    "\n",
    "label_dict = dict(zip(categories,labels))\n",
    "\n",
    "print('Categories: ', categories)\n",
    "print('Labels: ', labels)\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:  ['Train', 'Validation', 'Test']\n",
      "Paths:  ['Dataset/Train', 'Dataset/Validation', 'Dataset/Test']\n",
      "{'Train': 'Dataset/Train', 'Validation': 'Dataset/Validation', 'Test': 'Dataset/Test'}\n"
     ]
    }
   ],
   "source": [
    "datasets = ['Train', 'Validation', 'Test']\n",
    "paths = ['Dataset/Train', 'Dataset/Validation', 'Dataset/Test']\n",
    "\n",
    "path_dict = dict(zip(datasets, paths))\n",
    "\n",
    "print('Datasets: ', datasets)\n",
    "print('Paths: ', paths)\n",
    "print(path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Shape: (10000, 100, 100, 1)\n",
      "With Mask: 5000 (50.0%)\n",
      "Without Mask: 5000 (50.0%)\n",
      "\n",
      "Validation:\n",
      "Shape: (800, 100, 100, 1)\n",
      "With Mask: 400 (50.0%)\n",
      "Without Mask: 400 (50.0%)\n",
      "\n",
      "Test:\n",
      "Shape: (992, 100, 100, 1)\n",
      "With Mask: 483 (49.0%)\n",
      "Without Mask: 509 (51.0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_size = 100\n",
    "\n",
    "# Load data and target sets\n",
    "for dataset in datasets:\n",
    "    data = []\n",
    "    target = []\n",
    "\n",
    "    for category in categories:\n",
    "        folder_path = os.path.join(path_dict[dataset], category)\n",
    "        image_names = os.listdir(folder_path)\n",
    "\n",
    "        for image_name in image_names:\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            \n",
    "            try:\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Convert the image from RGB in GRAY scale because the RGB color image contains so\n",
    "                # much redundant information that is not necessary for face mask detection\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                # Resize the GRAY scale into 100x100 to maintain uniformity of the input images\n",
    "                resized = cv2.resize(gray, (image_size, image_size))\n",
    "\n",
    "                # Append the image and its label\n",
    "                data.append(resized)\n",
    "                target.append(label_dict[category])\n",
    "            \n",
    "            except Exception as e:\n",
    "                print('Failure: ', image_path)\n",
    "                print('Exception: ',e)\n",
    "\n",
    "    # Normalize the images in the range [0, 1]\n",
    "    data = np.array(data) / 255.0\n",
    "    # Reshape the images in 'channels last' format (samples, height, width, color_depth)\n",
    "    data = np.reshape(data, (data.shape[0], image_size, image_size, 1))\n",
    "    \n",
    "    target = np.array(target)\n",
    "    new_target = utils.to_categorical(target)\n",
    "\n",
    "    # Print dataset information\n",
    "    print(dataset + ':')\n",
    "    print('Shape: {}'.format(data.shape))\n",
    "    num_with_mask = np.sum(target == 0)\n",
    "    print('With Mask: {0} ({1}%)'.format(num_with_mask, round(num_with_mask / data.shape[0], 2) * 100))\n",
    "    num_without_mask = np.sum(target == 1)\n",
    "    print('Without Mask: {0} ({1}%)'.format(num_without_mask, round(num_without_mask / data.shape[0], 2) * 100))\n",
    "    print()\n",
    "   \n",
    "    # Save new dataset\n",
    "    np.save('DatasetPreprocessed/data_' + dataset, data)\n",
    "    np.save('DatasetPreprocessed/target_' + dataset, new_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp_venv",
   "language": "python",
   "name": "mlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
